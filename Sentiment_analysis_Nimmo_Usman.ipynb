{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NimmoUsman/test.12/blob/main/Sentiment_analysis_Nimmo_Usman.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2df65eb5",
      "metadata": {
        "id": "2df65eb5"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "42a25236",
      "metadata": {
        "id": "42a25236"
      },
      "source": [
        "# Sentiment Analysis of Restaurant Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53689c6b",
      "metadata": {
        "id": "53689c6b"
      },
      "outputs": [],
      "source": [
        "# The aim of this project is to predict the number of positive and negative reviews based on sentiments by using different classification models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0afa230",
      "metadata": {
        "id": "d0afa230"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d450a39",
      "metadata": {
        "scrolled": true,
        "id": "1d450a39"
      },
      "outputs": [],
      "source": [
        "r_data = pd.read_csv(\"Restaurant_Reviews.tsv\", sep='\\t' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e81520ca",
      "metadata": {
        "id": "e81520ca",
        "outputId": "868f70ba-60ac-4eb3-f9c7-2a3850b5bd8f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Liked\n",
              "0                           Wow... Loved this place.      1\n",
              "1                                 Crust is not good.      0\n",
              "2          Not tasty and the texture was just nasty.      0\n",
              "3  Stopped by during the late May bank holiday of...      1\n",
              "4  The selection on the menu was great and so wer...      1"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "r_data.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99f8803f",
      "metadata": {
        "id": "99f8803f",
        "outputId": "44e4c279-44d9-4f16-d13f-05792fea2a2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa8c5f08",
      "metadata": {
        "id": "aa8c5f08",
        "outputId": "28e1336b-a4d3-4a60-89a4-f5dddbb6a2a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Review  1000 non-null   object\n",
            " 1   Liked   1000 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 15.8+ KB\n"
          ]
        }
      ],
      "source": [
        "r_data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2b0b1e3",
      "metadata": {
        "id": "c2b0b1e3"
      },
      "source": [
        "# Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c5c8549",
      "metadata": {
        "id": "9c5c8549"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stop=stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3644c7a7",
      "metadata": {
        "id": "3644c7a7",
        "outputId": "d7fb76eb-5f6c-4747-a030-ace1d2b27228"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import string\n",
        "string.punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "738c114f",
      "metadata": {
        "id": "738c114f"
      },
      "outputs": [],
      "source": [
        "\n",
        "def count_punct(text):\n",
        "    count = sum([1 for char in text if char in string.punctuation])\n",
        "    return round(count/(len(text) - text.count(\" \")), 3)*100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "451960d6",
      "metadata": {
        "id": "451960d6"
      },
      "outputs": [],
      "source": [
        "def remove_punct(text):\n",
        "    clean_list = \"\".join([char for char in text if char not in string.punctuation])\n",
        "\n",
        "    return clean_list\n",
        "\n",
        "r_data['Review_text_clean'] = r_data['Review'].apply(remove_punct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22070787",
      "metadata": {
        "id": "22070787"
      },
      "outputs": [],
      "source": [
        "r_data['body_len'] = r_data['Review'].apply(lambda x: len(x) - x.count(\" \"))\n",
        "r_data['punct%'] = r_data['Review'].apply(lambda x: count_punct(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94369b0b",
      "metadata": {
        "id": "94369b0b",
        "outputId": "0d65f7c2-41dd-46e6-9d26-6b99218585e0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "      <th>Review_text_clean</th>\n",
              "      <th>body_len</th>\n",
              "      <th>punct%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "      <td>Wow Loved this place</td>\n",
              "      <td>21</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "      <td>Crust is not good</td>\n",
              "      <td>15</td>\n",
              "      <td>6.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "      <td>Not tasty and the texture was just nasty</td>\n",
              "      <td>34</td>\n",
              "      <td>2.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>73</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>48</td>\n",
              "      <td>2.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Liked  \\\n",
              "0                           Wow... Loved this place.      1   \n",
              "1                                 Crust is not good.      0   \n",
              "2          Not tasty and the texture was just nasty.      0   \n",
              "3  Stopped by during the late May bank holiday of...      1   \n",
              "4  The selection on the menu was great and so wer...      1   \n",
              "\n",
              "                                   Review_text_clean  body_len  punct%  \n",
              "0                               Wow Loved this place        21    19.0  \n",
              "1                                  Crust is not good        15     6.7  \n",
              "2           Not tasty and the texture was just nasty        34     2.9  \n",
              "3  Stopped by during the late May bank holiday of...        73     1.4  \n",
              "4  The selection on the menu was great and so wer...        48     2.1  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f53c5344",
      "metadata": {
        "id": "f53c5344",
        "outputId": "1f265c52-efe7-4a98-be76-d11ca60657a3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "      <th>Review_text_clean</th>\n",
              "      <th>body_len</th>\n",
              "      <th>punct%</th>\n",
              "      <th>Review_text_tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "      <td>Wow Loved this place</td>\n",
              "      <td>21</td>\n",
              "      <td>19.0</td>\n",
              "      <td>[wow, loved, this, place]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "      <td>Crust is not good</td>\n",
              "      <td>15</td>\n",
              "      <td>6.7</td>\n",
              "      <td>[crust, is, not, good]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "      <td>Not tasty and the texture was just nasty</td>\n",
              "      <td>34</td>\n",
              "      <td>2.9</td>\n",
              "      <td>[not, tasty, and, the, texture, was, just, nasty]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>73</td>\n",
              "      <td>1.4</td>\n",
              "      <td>[stopped, by, during, the, late, may, bank, ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>48</td>\n",
              "      <td>2.1</td>\n",
              "      <td>[the, selection, on, the, menu, was, great, an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Liked  \\\n",
              "0                           Wow... Loved this place.      1   \n",
              "1                                 Crust is not good.      0   \n",
              "2          Not tasty and the texture was just nasty.      0   \n",
              "3  Stopped by during the late May bank holiday of...      1   \n",
              "4  The selection on the menu was great and so wer...      1   \n",
              "\n",
              "                                   Review_text_clean  body_len  punct%  \\\n",
              "0                               Wow Loved this place        21    19.0   \n",
              "1                                  Crust is not good        15     6.7   \n",
              "2           Not tasty and the texture was just nasty        34     2.9   \n",
              "3  Stopped by during the late May bank holiday of...        73     1.4   \n",
              "4  The selection on the menu was great and so wer...        48     2.1   \n",
              "\n",
              "                               Review_text_tokenized  \n",
              "0                          [wow, loved, this, place]  \n",
              "1                             [crust, is, not, good]  \n",
              "2  [not, tasty, and, the, texture, was, just, nasty]  \n",
              "3  [stopped, by, during, the, late, may, bank, ho...  \n",
              "4  [the, selection, on, the, menu, was, great, an...  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def tokenize(text):\n",
        "    tokens = re.split('\\W+', text)\n",
        "    return tokens\n",
        "r_data['Review_text_tokenized'] = r_data['Review_text_clean'].apply(lambda x: tokenize(x.lower()))\n",
        "\n",
        "r_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc45429f",
      "metadata": {
        "id": "dc45429f",
        "outputId": "158830b4-a6b7-44e2-cef7-2bd2794beffe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\DPSYOPS\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "      <th>Review_text_clean</th>\n",
              "      <th>body_len</th>\n",
              "      <th>punct%</th>\n",
              "      <th>Review_text_tokenized</th>\n",
              "      <th>Review_text_nostop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "      <td>Wow Loved this place</td>\n",
              "      <td>21</td>\n",
              "      <td>19.0</td>\n",
              "      <td>[wow, loved, this, place]</td>\n",
              "      <td>[wow, loved, place]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "      <td>Crust is not good</td>\n",
              "      <td>15</td>\n",
              "      <td>6.7</td>\n",
              "      <td>[crust, is, not, good]</td>\n",
              "      <td>[crust, good]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "      <td>Not tasty and the texture was just nasty</td>\n",
              "      <td>34</td>\n",
              "      <td>2.9</td>\n",
              "      <td>[not, tasty, and, the, texture, was, just, nasty]</td>\n",
              "      <td>[tasty, texture, nasty]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>73</td>\n",
              "      <td>1.4</td>\n",
              "      <td>[stopped, by, during, the, late, may, bank, ho...</td>\n",
              "      <td>[stopped, late, may, bank, holiday, rick, stev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>48</td>\n",
              "      <td>2.1</td>\n",
              "      <td>[the, selection, on, the, menu, was, great, an...</td>\n",
              "      <td>[selection, menu, great, prices]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Liked  \\\n",
              "0                           Wow... Loved this place.      1   \n",
              "1                                 Crust is not good.      0   \n",
              "2          Not tasty and the texture was just nasty.      0   \n",
              "3  Stopped by during the late May bank holiday of...      1   \n",
              "4  The selection on the menu was great and so wer...      1   \n",
              "\n",
              "                                   Review_text_clean  body_len  punct%  \\\n",
              "0                               Wow Loved this place        21    19.0   \n",
              "1                                  Crust is not good        15     6.7   \n",
              "2           Not tasty and the texture was just nasty        34     2.9   \n",
              "3  Stopped by during the late May bank holiday of...        73     1.4   \n",
              "4  The selection on the menu was great and so wer...        48     2.1   \n",
              "\n",
              "                               Review_text_tokenized  \\\n",
              "0                          [wow, loved, this, place]   \n",
              "1                             [crust, is, not, good]   \n",
              "2  [not, tasty, and, the, texture, was, just, nasty]   \n",
              "3  [stopped, by, during, the, late, may, bank, ho...   \n",
              "4  [the, selection, on, the, menu, was, great, an...   \n",
              "\n",
              "                                  Review_text_nostop  \n",
              "0                                [wow, loved, place]  \n",
              "1                                      [crust, good]  \n",
              "2                            [tasty, texture, nasty]  \n",
              "3  [stopped, late, may, bank, holiday, rick, stev...  \n",
              "4                   [selection, menu, great, prices]  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stopword = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def remove_stopwords(tokenized_list):\n",
        "    text = [word for word in tokenized_list if word not in stopword]\n",
        "    return text\n",
        "\n",
        "r_data['Review_text_nostop'] = r_data['Review_text_tokenized'].apply(lambda x: remove_stopwords(x))\n",
        "\n",
        "r_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcbf1bb6",
      "metadata": {
        "id": "fcbf1bb6",
        "outputId": "5054e017-35e9-406a-92fc-7acfb1dd13f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "      <th>Review_text_clean</th>\n",
              "      <th>body_len</th>\n",
              "      <th>punct%</th>\n",
              "      <th>Review_text_tokenized</th>\n",
              "      <th>Review_text_nostop</th>\n",
              "      <th>Review_text_stemmed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "      <td>Wow Loved this place</td>\n",
              "      <td>21</td>\n",
              "      <td>19.0</td>\n",
              "      <td>[wow, loved, this, place]</td>\n",
              "      <td>[wow, loved, place]</td>\n",
              "      <td>[wow, love, place]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "      <td>Crust is not good</td>\n",
              "      <td>15</td>\n",
              "      <td>6.7</td>\n",
              "      <td>[crust, is, not, good]</td>\n",
              "      <td>[crust, good]</td>\n",
              "      <td>[crust, good]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "      <td>Not tasty and the texture was just nasty</td>\n",
              "      <td>34</td>\n",
              "      <td>2.9</td>\n",
              "      <td>[not, tasty, and, the, texture, was, just, nasty]</td>\n",
              "      <td>[tasty, texture, nasty]</td>\n",
              "      <td>[tasti, textur, nasti]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>73</td>\n",
              "      <td>1.4</td>\n",
              "      <td>[stopped, by, during, the, late, may, bank, ho...</td>\n",
              "      <td>[stopped, late, may, bank, holiday, rick, stev...</td>\n",
              "      <td>[stop, late, may, bank, holiday, rick, steve, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>48</td>\n",
              "      <td>2.1</td>\n",
              "      <td>[the, selection, on, the, menu, was, great, an...</td>\n",
              "      <td>[selection, menu, great, prices]</td>\n",
              "      <td>[select, menu, great, price]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Liked  \\\n",
              "0                           Wow... Loved this place.      1   \n",
              "1                                 Crust is not good.      0   \n",
              "2          Not tasty and the texture was just nasty.      0   \n",
              "3  Stopped by during the late May bank holiday of...      1   \n",
              "4  The selection on the menu was great and so wer...      1   \n",
              "\n",
              "                                   Review_text_clean  body_len  punct%  \\\n",
              "0                               Wow Loved this place        21    19.0   \n",
              "1                                  Crust is not good        15     6.7   \n",
              "2           Not tasty and the texture was just nasty        34     2.9   \n",
              "3  Stopped by during the late May bank holiday of...        73     1.4   \n",
              "4  The selection on the menu was great and so wer...        48     2.1   \n",
              "\n",
              "                               Review_text_tokenized  \\\n",
              "0                          [wow, loved, this, place]   \n",
              "1                             [crust, is, not, good]   \n",
              "2  [not, tasty, and, the, texture, was, just, nasty]   \n",
              "3  [stopped, by, during, the, late, may, bank, ho...   \n",
              "4  [the, selection, on, the, menu, was, great, an...   \n",
              "\n",
              "                                  Review_text_nostop  \\\n",
              "0                                [wow, loved, place]   \n",
              "1                                      [crust, good]   \n",
              "2                            [tasty, texture, nasty]   \n",
              "3  [stopped, late, may, bank, holiday, rick, stev...   \n",
              "4                   [selection, menu, great, prices]   \n",
              "\n",
              "                                 Review_text_stemmed  \n",
              "0                                 [wow, love, place]  \n",
              "1                                      [crust, good]  \n",
              "2                             [tasti, textur, nasti]  \n",
              "3  [stop, late, may, bank, holiday, rick, steve, ...  \n",
              "4                       [select, menu, great, price]  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "def stemming(tokenized_text):\n",
        "    text = [ps.stem(word) for word in tokenized_text]\n",
        "    return text\n",
        "\n",
        "r_data['Review_text_stemmed'] = r_data['Review_text_nostop'].apply(lambda x: stemming(x))\n",
        "\n",
        "r_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de7b7cec",
      "metadata": {
        "id": "de7b7cec",
        "outputId": "6fae9aaf-d5a8-4b6c-9bae-71dabc36e07f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\DPSYOPS\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\DPSYOPS\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a67fcd9a",
      "metadata": {
        "id": "a67fcd9a"
      },
      "outputs": [],
      "source": [
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8aceae8e",
      "metadata": {
        "id": "8aceae8e",
        "outputId": "eccac88f-8e11-4d36-c123-7ceb7059d288"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "      <th>Review_text_clean</th>\n",
              "      <th>body_len</th>\n",
              "      <th>punct%</th>\n",
              "      <th>Review_text_tokenized</th>\n",
              "      <th>Review_text_nostop</th>\n",
              "      <th>Review_text_stemmed</th>\n",
              "      <th>Rewview_text_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "      <td>Wow Loved this place</td>\n",
              "      <td>21</td>\n",
              "      <td>19.0</td>\n",
              "      <td>[wow, loved, this, place]</td>\n",
              "      <td>[wow, loved, place]</td>\n",
              "      <td>[wow, love, place]</td>\n",
              "      <td>[wow, loved, place]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "      <td>Crust is not good</td>\n",
              "      <td>15</td>\n",
              "      <td>6.7</td>\n",
              "      <td>[crust, is, not, good]</td>\n",
              "      <td>[crust, good]</td>\n",
              "      <td>[crust, good]</td>\n",
              "      <td>[crust, good]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "      <td>Not tasty and the texture was just nasty</td>\n",
              "      <td>34</td>\n",
              "      <td>2.9</td>\n",
              "      <td>[not, tasty, and, the, texture, was, just, nasty]</td>\n",
              "      <td>[tasty, texture, nasty]</td>\n",
              "      <td>[tasti, textur, nasti]</td>\n",
              "      <td>[tasty, texture, nasty]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>73</td>\n",
              "      <td>1.4</td>\n",
              "      <td>[stopped, by, during, the, late, may, bank, ho...</td>\n",
              "      <td>[stopped, late, may, bank, holiday, rick, stev...</td>\n",
              "      <td>[stop, late, may, bank, holiday, rick, steve, ...</td>\n",
              "      <td>[stopped, late, may, bank, holiday, rick, stev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>48</td>\n",
              "      <td>2.1</td>\n",
              "      <td>[the, selection, on, the, menu, was, great, an...</td>\n",
              "      <td>[selection, menu, great, prices]</td>\n",
              "      <td>[select, menu, great, price]</td>\n",
              "      <td>[selection, menu, great, price]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Liked  \\\n",
              "0                           Wow... Loved this place.      1   \n",
              "1                                 Crust is not good.      0   \n",
              "2          Not tasty and the texture was just nasty.      0   \n",
              "3  Stopped by during the late May bank holiday of...      1   \n",
              "4  The selection on the menu was great and so wer...      1   \n",
              "\n",
              "                                   Review_text_clean  body_len  punct%  \\\n",
              "0                               Wow Loved this place        21    19.0   \n",
              "1                                  Crust is not good        15     6.7   \n",
              "2           Not tasty and the texture was just nasty        34     2.9   \n",
              "3  Stopped by during the late May bank holiday of...        73     1.4   \n",
              "4  The selection on the menu was great and so wer...        48     2.1   \n",
              "\n",
              "                               Review_text_tokenized  \\\n",
              "0                          [wow, loved, this, place]   \n",
              "1                             [crust, is, not, good]   \n",
              "2  [not, tasty, and, the, texture, was, just, nasty]   \n",
              "3  [stopped, by, during, the, late, may, bank, ho...   \n",
              "4  [the, selection, on, the, menu, was, great, an...   \n",
              "\n",
              "                                  Review_text_nostop  \\\n",
              "0                                [wow, loved, place]   \n",
              "1                                      [crust, good]   \n",
              "2                            [tasty, texture, nasty]   \n",
              "3  [stopped, late, may, bank, holiday, rick, stev...   \n",
              "4                   [selection, menu, great, prices]   \n",
              "\n",
              "                                 Review_text_stemmed  \\\n",
              "0                                 [wow, love, place]   \n",
              "1                                      [crust, good]   \n",
              "2                             [tasti, textur, nasti]   \n",
              "3  [stop, late, may, bank, holiday, rick, steve, ...   \n",
              "4                       [select, menu, great, price]   \n",
              "\n",
              "                             Rewview_text_lemmatized  \n",
              "0                                [wow, loved, place]  \n",
              "1                                      [crust, good]  \n",
              "2                            [tasty, texture, nasty]  \n",
              "3  [stopped, late, may, bank, holiday, rick, stev...  \n",
              "4                    [selection, menu, great, price]  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def lemmatizing(tokenized_text):\n",
        "    text = [lemmatizer.lemmatize(word) for word in tokenized_text]\n",
        "    return text\n",
        "\n",
        "r_data['Rewview_text_lemmatized'] = r_data['Review_text_nostop'].apply(lambda x: lemmatizing(x))\n",
        "\n",
        "r_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a55bf0e7",
      "metadata": {
        "id": "a55bf0e7",
        "outputId": "ee40c876-2550-4369-efde-736e9486b6ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 2067)\n",
            "['10', '100', '1199', '12', '15', '15lb', '17', '1979', '20', '2007', '23', '30', '30s', '34ths', '35', '40', '400', '40min', '45', '70', '785', '90', 'about', 'above', 'absolute', 'absolutely', 'absolutley', 'accident', 'accommodations', 'accomodate', 'accordingly', 'accountant', 'ache', 'acknowledged', 'across', 'actual', 'actually', 'added', 'affordable', 'after', 'afternoon', 'again', 'ago', 'ahead', 'airline', 'airport', 'ala', 'albondigas', 'all', 'allergy', 'almonds', 'almost', 'alone', 'also', 'although', 'always', 'am', 'amazing', 'amazingrge', 'ambiance', 'ambience', 'amount', 'ample', 'an', 'and', 'andddd', 'angry', 'another', 'anticipated', 'any', 'anymore', 'anyone', 'anything', 'anytime', 'anyway', 'anyways', 'apart', 'apologize', 'apology', 'app', 'appalling', 'apparently', 'appealing', 'appetite', 'appetizer', 'appetizers', 'apple', 'approval', 'are', 'area', 'arent', 'arepas', 'aria', 'around', 'array', 'arrived', 'arrives', 'arriving', 'article', 'as', 'ask', 'asked', 'asking', 'assure', 'at', 'ate', 'atmosphere', 'atmosphere1', 'atrocious', 'attached', 'attack', 'attention', 'attentive', 'attitudes', 'auju', 'authentic', 'average', 'avocado', 'avoid', 'avoided', 'away', 'awesome', 'awful', 'awkward', 'awkwardly', 'ayce', 'az', 'baba', 'baby', 'bachi', 'back', 'bacon', 'bad', 'bagels', 'bakery', 'baklava', 'ball', 'bamboo', 'banana', 'bank', 'bar', 'bare', 'barely', 'bargain', 'bars', 'bartender', 'bartenders', 'baseball', 'based', 'basically', 'batch', 'bathroom', 'bathrooms', 'batter', 'bay', 'bbq', 'be', 'bean', 'beans', 'beat', 'beateous', 'beautiful', 'beautifully', 'beauty', 'because', 'become', 'beef', 'been', 'beensteppedinandtrackedeverywhere', 'beer', 'beers', 'before', 'begin', 'behind', 'being', 'believe', 'bellagio', 'bellies', 'belly', 'below', 'besides', 'best', 'better', 'between', 'beyond', 'big', 'bigger', 'biggest', 'bill', 'binge', 'bird', 'biscuit', 'biscuits', 'bisque', 'bit', 'bitches', 'bite', 'bites', 'bits', 'black', 'blah', 'blame', 'bland', 'blandest', 'blanket', 'block', 'bloddy', 'bloodiest', 'bloody', 'blow', 'blown', 'blows', 'blue', 'boba', 'bodes', 'boiled', 'bone', 'booksomethats', 'boot', 'boring', 'both', 'bother', 'bottom', 'bouchon', 'bought', 'bowl', 'box', 'boxes', 'boy', 'boyfriend', 'boys', 'bread', 'break', 'breakfast', 'breakfastlunch', 'breaks', 'breeze', 'brick', 'bring', 'brings', 'brisket', 'brother', 'brought', 'brownish', 'brunch', 'bruschetta', 'brushfire', 'bucks', 'buffet', 'buffets', 'bug', 'building', 'buldogis', 'bunch', 'burger', 'burgers', 'burned', 'burrittos', 'bus', 'business', 'businesses', 'bussell', 'busy', 'but', 'butter', 'buying', 'by', 'bye', 'caballeros', 'caesar', 'cafe', 'café', 'cakeohhh', 'cakes', 'calamari', 'call', 'calligraphy', 'callings', 'came', 'camelback', 'can', 'cannoli', 'cannot', 'cant', 'cape', 'capers', 'car', 'carbs', 'care', 'caring', 'carlys', 'carpaccio', 'cart', 'cartel', 'case', 'cash', 'cashew', 'cashier', 'casino', 'caterpillar', 'caught', 'cause', 'cavier', 'certainly', 'chai', 'chains', 'changing', 'char', 'charcoal', 'charge', 'charged', 'charming', 'cheap', 'cheated', 'check', 'checked', 'cheek', 'cheese', 'cheeseburger', 'cheesecurds', 'chef', 'chefs', 'chewy', 'chicken', 'chickens', 'chinese', 'chip', 'chipolte', 'chipotle', 'chips', 'chocolate', 'choose', 'choux', 'chow', 'christmas', 'cibo', 'circumstances', 'claimed', 'class', 'classic', 'classics', 'classywarm', 'clean', 'climbing', 'close', 'closed', 'club', 'clue', 'cocktail', 'cocktails', 'coconut', 'cod', 'coffee', 'cold', 'colder', 'college', 'color', 'combination', 'combo', 'combos', 'come', 'comfortable', 'coming', 'common', 'companions', 'company', 'complain', 'complaints', 'complete', 'completely', 'compliments', 'con', 'concept', 'concern', 'conclusion', 'condiment', 'connoisseur', 'consider', 'considering', 'consistent', 'constructed', 'contain', 'contained', 'containers', 'continue', 'convenient', 'cook', 'cooked', 'cooking', 'cool', 'corn', 'corporation', 'correct', 'correction', 'cost', 'costcos', 'cotta', 'could', 'couldnt', 'count', 'couple', 'couples', 'coupons', 'course', 'court', 'courteous', 'cover', 'covered', 'covers', 'cow', 'coziness', 'crab', 'cramming', 'cranberrymmmm', 'craving', 'crawfish', 'crazy', 'cream', 'creamy', 'crema', 'crepe', 'crisp', 'crispy', 'crostini', 'croutons', 'crowd', 'crowds', 'crumby', 'crust', 'crusty', 'crystals', 'crêpe', 'cuisine', 'curry', 'customer', 'customers', 'customize', 'cut', 'cute', 'daily', 'damn', 'dark', 'date', 'dates', 'daughter', 'day', 'dead', 'deal', 'dealing', 'decent', 'decide', 'decided', 'decision', 'decor', 'decorated', 'dedicated', 'deep', 'deeply', 'def', 'definately', 'definitely', 'degree', 'del', 'delicate', 'delicioso', 'delicious', 'deliciously', 'delight', 'delightful', 'delights', 'delish', 'deliver', 'delivery', 'dennys', 'describing', 'descriptions', 'deserves', 'desired', 'despicable', 'despite', 'dessert', 'desserts', 'deuchebaggery', 'devine', 'did', 'didnt', 'die', 'difference', 'different', 'dime', 'dine', 'dining', 'dinner', 'dinners', 'dipping', 'dirt', 'dirty', 'disagree', 'disappoint', 'disappointed', 'disappointing', 'disappointment', 'disapppointment', 'disaster', 'disbelief', 'discount', 'disgrace', 'disgraceful', 'disgust', 'disgusted', 'disgusting', 'dish', 'dishes', 'dispenser', 'disrespected', 'diverse', 'do', 'does', 'dog', 'doing', 'dollars', 'done', 'dont', 'donut', 'door', 'dos', 'double', 'doubt', 'douchey', 'dough', 'doughy', 'down', 'downright', 'downside', 'downtown', 'drag', 'drastically', 'drawing', 'dreamed', 'drenched', 'dressed', 'dressing', 'dried', 'driest', 'drink', 'drinking', 'drinks', 'dripping', 'drive', 'driving', 'dropped', 'drunk', 'dry', 'duck', 'dude', 'due', 'duo', 'during', 'dusted', 'dylan', 'each', 'easily', 'eat', 'eaten', 'eating', 'eclectic', 'edible', 'edinburgh', 'editing', 'eel', 'eew', 'efficient', 'effort', 'egg', 'eggplant', 'eggs', 'either', 'elegantly', 'elk', 'else', 'elsewhere', 'email', 'employee', 'employees', 'empty', 'end', 'ended', 'english', 'enjoy', 'enjoyable', 'enjoyed', 'enough', 'ensued', 'enthusiastic', 'entire', 'entrees', 'equally', 'especially', 'establishment', 'etc', 'ethic', 'eve', 'even', 'evening', 'event', 'events', 'ever', 'every', 'everyone', 'everything', 'exactly', 'excalibur', 'exceeding', 'excellent', 'exceptional', 'excuse', 'expanded', 'expect', 'expectations', 'expected', 'expensive', 'experience', 'experienced', 'experiencing', 'expertconnisseur', 'exquisite', 'extensive', 'extra', 'extraordinary', 'extremely', 'eyed', 'eyes', 'fabulous', 'fact', 'fail', 'fails', 'fair', 'fairly', 'falafels', 'falling', 'familiar', 'family', 'famous', 'fan', 'fantastic', 'far', 'fare', 'fast', 'fat', 'fav', 'favor', 'favorite', 'fear', 'feel', 'feeling', 'feels', 'fell', 'fella', 'fellow', 'felt', 'few', 'fiancé', 'figured', 'filet', 'fill', 'fillet', 'filling', 'final', 'finally', 'find', 'fine', 'finger', 'finish', 'fireball', 'firehouse', 'first', 'fish', 'five', 'flair', 'flat', 'flatlined', 'flavor', 'flavored', 'flavorful', 'flavorless', 'flavors', 'flavourful', 'flirting', 'flop', 'flower', 'fluffy', 'fly', 'fo', 'focused', 'folks', 'fondue', 'food', 'foodand', 'foods', 'foodservice', 'foot', 'for', 'forever', 'forgetting', 'forth', 'forty', 'forward', 'found', 'four', 'francisco', 'freaking', 'free', 'freezing', 'frenchman', 'fresh', 'fridays', 'fried', 'friend', 'friendly', 'friends', 'fries', 'from', 'front', 'frozen', 'fruit', 'frustrated', 'fry', 'fs', 'fucking', 'full', 'fun', 'funny', 'further', 'furthermore', 'fuzzy', 'ganoush', 'garden', 'garlic', 'gas', 'gave', 'gc', 'gem', 'generic', 'generous', 'genuinely', 'get', 'gets', 'getting', 'giant', 'girlfriends', 'give', 'given', 'giving', 'glad', 'glance', 'glass', 'gloveseverything', 'gluten', 'go', 'goat', 'godfathers', 'going', 'gold', 'goldencrispy', 'gone', 'good', 'google', 'gooodd', 'gordon', 'got', 'gotten', 'gourmet', 'grab', 'grandmother', 'gratitude', 'gratuity', 'grease', 'greasy', 'great', 'greatest', 'greedy', 'greek', 'green', 'greens', 'greeted', 'grill', 'grilled', 'gringos', 'gristle', 'grocery', 'gross', 'grossed', 'ground', 'group', 'groups', 'grow', 'guacamole', 'guess', 'guest', 'guests', 'guy', 'guys', 'gyro', 'gyros', 'ha', 'had', 'hadnt', 'hair', 'half', 'halibut', 'hamburger', 'han', 'hand', 'handed', 'handled', 'handling', 'handmade', 'hands', 'handsdown', 'hankering', 'happened', 'happier', 'happy', 'hard', 'hardest', 'hardly', 'has', 'hasnt', 'hate', 'hated', 'haunt', 'have', 'havent', 'having', 'hawaiian', 'he', 'head', 'heads', 'healthy', 'heard', 'heart', 'hearts', 'heat', 'heimer', 'held', 'hell', 'hella', 'hello', 'help', 'helped', 'helpful', 'her', 'here', 'hereas', 'herewhat', 'hes', 'hi', 'high', 'highlight', 'highlighted', 'highlights', 'highly', 'highquality', 'hilarious', 'him', 'hip', 'hiro', 'his', 'hit', 'hits', 'hole', 'holiday', 'home', 'homemade', 'honeslty', 'honest', 'honestly', 'honor', 'hooked', 'hope', 'hopefully', 'hopes', 'hoping', 'horrible', 'hospitality', 'host', 'hostess', 'hot', 'hottest', 'hour', 'hours', 'house', 'how', 'however', 'huevos', 'huge', 'human', 'humiliated', 'hummus', 'hunan', 'hungry', 'hurry', 'husband', 'hut', 'ians', 'ice', 'iced', 'id', 'idea', 'if', 'ignore', 'ignored', 'ill', 'im', 'imagination', 'imaginative', 'imagine', 'imagined', 'immediately', 'impeccable', 'impressed', 'impressive', 'in', 'inch', 'included', 'including', 'inconsiderate', 'incredible', 'incredibly', 'indian', 'indicate', 'indoor', 'industry', 'inexpensive', 'inflate', 'informative', 'ingredients', 'inhouse', 'insanely', 'inside', 'inspired', 'instantly', 'instead', 'insulted', 'insults', 'interesting', 'interior', 'into', 'inviting', 'ironman', 'is', 'isnt', 'it', 'italian', 'itdefinitely', 'item', 'itfriendly', 'itll', 'its', 'itself', 'ive', 'jalapeno', 'jamaican', 'japanese', 'jeff', 'jenni', 'jerk', 'jewel', 'job', 'joeys', 'join', 'joint', 'joke', 'joy', 'judge', 'judging', 'juice', 'juries', 'just', 'kabuki', 'kept', 'khao', 'kiddos', 'kids', 'killer', 'kind', 'kitchen', 'know', 'known', 'lack', 'lacked', 'lacking', 'ladies', 'lady', 'large', 'largely', 'larger', 'las', 'last', 'lastly', 'late', 'later', 'latte', 'law', 'lawyers', 'least', 'leather', 'leave', 'leaves', 'left', 'leftover', 'legit', 'legs', 'lemon', 'less', 'let', 'letdown', 'lets', 'letting', 'lettuce', 'level', 'life', 'light', 'lighter', 'lighting', 'lightly', 'like', 'liked', 'likes', 'liking', 'lil', 'limited', 'list', 'listed', 'literally', 'little', 'live', 'lived', 'living', 'lobster', 'located', 'location', 'long', 'longer', 'look', 'looked', 'looking', 'looks', 'lordy', 'lost', 'lot', 'lots', 'loudly', 'love', 'loved', 'lovely', 'lover', 'lovers', 'loves', 'loving', 'low', 'lowkey', 'lox', 'loyal', 'luck', 'luke', 'lukewarm', 'lunch', 'mac', 'macarons', 'made', 'madhouse', 'madison', 'magazine', 'magic', 'main', 'maine', 'mains', 'maintaining', 'make', 'making', 'mall', 'man', 'managed', 'management', 'manager', 'mandalay', 'mango', 'many', 'margaritas', 'maria', 'market', 'marrow', 'martini', 'mary', 'marys', 'massive', 'may', 'maybe', 'mayo', 'mayowell', 'me', 'meal', 'meals', 'mean', 'means', 'meat', 'meatballs', 'meatloaf', 'meats', 'mebunch', 'mediocre', 'mediterranean', 'medium', 'meet', 'meeverything', 'meh', 'mein', 'mellow', 'melt', 'melted', 'memory', 'mention', 'menu', 'menus', 'mesquite', 'mess', 'metro', 'mexican', 'mgm', 'mid', 'middle', 'might', 'mile', 'military', 'milk', 'milkshake', 'min', 'mind', 'minutes', 'mirage', 'miss', 'missed', 'missing', 'mistake', 'mixed', 'mmmm', 'modern', 'moist', 'mojitos', 'mom', 'moms', 'money', 'monster', 'months', 'mood', 'moods', 'more', 'mortified', 'most', 'mostly', 'mouth', 'mouthful', 'mouths', 'movies', 'moz', 'mozzarella', 'ms', 'much', 'muffin', 'multigrain', 'multiple', 'mushroom', 'mushrooms', 'music', 'mussels', 'must', 'muststop', 'my', 'myself', 'naan', 'nachos', 'name', 'nan', 'nargile', 'nasty', 'nay', 'nearly', 'neat', 'need', 'needed', 'needless', 'needs', 'negligent', 'neighborhood', 'neither', 'never', 'new', 'next', 'nice', 'nicest', 'night', 'nigiri', 'ninja', 'no', 'nobu', 'noca', 'noncustomer', 'none', 'nonfancy', 'noodles', 'north', 'not', 'note', 'nothing', 'now', 'nude', 'number', 'nut', 'nutshell', 'nyc', 'obviously', 'occasional', 'occasions', 'of', 'off', 'offered', 'offers', 'officially', 'oh', 'oil', 'ok', 'old', 'older', 'olives', 'omelets', 'omg', 'on', 'once', 'one', 'ones', 'onion', 'only', 'opened', 'operation', 'opinion', 'opportunity', 'opposed', 'options', 'or', 'order', 'ordered', 'ordering', 'orders', 'original', 'other', 'others', 'otherwise', 'otto', 'our', 'ourselves', 'out', 'outdoor', 'outrageously', 'outshining', 'outside', 'outstanding', 'outta', 'oven', 'over', 'overall', 'overcooked', 'overhaul', 'overhip', 'overpriced', 'overwhelm', 'overwhelmed', 'owned', 'owner', 'ownerchef', 'owners', 'oysters', 'pace', 'pack', 'packed', 'paid', 'palate', 'pale', 'palm', 'pan', 'pancake', 'pancakes', 'panna', 'paper', 'papers', 'par', 'paradise', 'parents', 'part', 'particular', 'parties', 'party', 'passed', 'past', 'pasta', 'pastas', 'pastry', 'patio', 'patron', 'pats', 'patty', 'pay', 'paying', 'peach', 'peanut', 'peanuts', 'pears', 'peas', 'pecan', 'penne', 'people', 'pepper', 'pepperand', 'perfect', 'perfection', 'perfectly', 'performed', 'perhaps', 'perpared', 'person', 'personable', 'personally', 'petrified', 'petty', 'phenomenal', 'philadelphia', 'pho', 'phoenix', 'piano', 'picture', 'pictures', 'piece', 'pile', 'pine', 'pineapple', 'pink', 'pissd', 'pita', 'pizza', 'pizzas', 'place', 'placed', 'places', 'plain', 'plantains', 'plastic', 'plate', 'plater', 'platter', 'play', 'playing', 'pleasant', 'please', 'pleased', 'pleasure', 'plethora', 'plus', 'pneumatic', 'point', 'poisoning', 'polite', 'poop', 'poor', 'poorly', 'pop', 'pork', 'portion', 'portions', 'positive', 'possible', 'postinos', 'potato', 'potatoes', 'poured', 'powdered', 'power', 'prefer', 'prepare', 'prepared', 'preparing', 'presentation', 'pretty', 'prettyoff', 'price', 'priced', 'prices', 'pricey', 'pricing', 'prime', 'privileged', 'probably', 'problem', 'proclaimed', 'professional', 'profiterole', 'profound', 'promise', 'prompt', 'promptly', 'properly', 'pros', 'proven', 'provided', 'provides', 'providing', 'pub', 'public', 'publicly', 'pucks', 'pulled', 'pumpkin', 'puree', 'puréed', 'put', 'putting', 'quaint', 'qualified', 'quality', 'quantity', 'quick', 'quickly', 'quit', 'quite', 'ramseys', 'ranch', 'rancheros', 'rapidly', 'rare', 'rarely', 'raspberry', 'rate', 'rated', 'rather', 'rating', 'ratio', 'rave', 'raving', 'ravoli', 'read', 'readers', 'reading', 'real', 'realized', 'really', 'reason', 'reasonable', 'reasonably', 'reasons', 'recall', 'received', 'receives', 'recent', 'recently', 'recommend', 'recommendation', 'recommended', 'recommending', 'red', 'redeeming', 'reduction', 'refill', 'refrained', 'refreshing', 'refried', 'refused', 'register', 'regular', 'regularly', 'reheated', 'relationship', 'relax', 'relaxed', 'relleno', 'relocated', 'remember', 'reminded', 'reminds', 'replenished', 'requested', 'reservation', 'rest', 'restaraunt', 'restaurant', 'restaurants', 'return', 'returned', 'returning', 'review', 'reviewer', 'reviewing', 'reviews', 'revisiting', 'ri', 'rib', 'ribeye', 'rice', 'rich', 'rick', 'ridiculous', 'right', 'rightthe', 'rings', 'rinse', 'ripped', 'risotto', 'roast', 'roasted', 'rock', 'roll', 'rolled', 'rolls', 'room', 'rotating', 'round', 'rowdy', 'rubber', 'rude', 'rudely', 'running', 'rushed', 'ryans', 'sad', 'sadly', 'saffron', 'saganaki', 'said', 'salad', 'salads', 'salmon', 'sals', 'salsa', 'salt', 'salty', 'same', 'sample', 'san', 'sandwich', 'sandwiches', 'sangria', 'sashimi', 'sat', 'satifying', 'satisfied', 'satisfying', 'sauce', 'sauces', 'sause', 'saving', 'say', 'saying', 'says', 'scallop', 'scene', 'scottsdale', 'screams', 'screwed', 'seafood', 'seal', 'seasonal', 'seasoned', 'seasoning', 'seat', 'seated', 'seating', 'second', 'section', 'see', 'seemed', 'seems', 'seen', 'selection', 'selections', 'self', 'send', 'sense', 'sergeant', 'seriously', 'serivce', 'serve', 'served', 'server', 'servers', 'serves', 'service', 'servicecheck', 'services', 'serving', 'set', 'setting', 'sever', 'several', 'sewer', 'sexy', 'shall', 'sharply', 'shawarrrrrrma', 'she', 'shirt', 'shocked', 'shoe', 'shoots', 'shop', 'shopping', 'shops', 'short', 'shots', 'should', 'shouldnt', 'show', 'showed', 'shower', 'shrimp', 'sick', 'side', 'sides', 'sign', 'signs', 'silently', 'similar', 'similarly', 'simple', 'simply', 'since', 'single', 'sitdown', 'sitting', 'six', 'skimp', 'slaw', 'sliced', 'slices', 'slow', 'small', 'smaller', 'smashburger', 'smeared', 'smelled', 'smells', 'smoke', 'smooth', 'smoothies', 'so', 'soggy', 'soi', 'solid', 'solidify', 'some', 'somehow', 'someone', 'something', 'somewhat', 'son', 'songs', 'soon', 'soooo', 'sooooo', 'soooooo', 'sore', 'sorely', 'sorry', 'sound', 'soundtrack', 'soup', 'soups', 'sour', 'southwest', 'space', 'spaghetti', 'special', 'specialand', 'specials', 'speedy', 'spend', 'spends', 'spice', 'spices', 'spicier', 'spicy', 'spinach', 'sporting', 'spot', 'spots', 'spotty', 'spring', 'sprouts', 'staff', 'stale', 'standard', 'star', 'stars', 'started', 'starving', 'station', 'stay', 'stayed', 'staying', 'steak', 'steakhouse', 'steaks', 'steiners', 'step', 'stepped', 'steve', 'sticks', 'still', 'stinks', 'stir', 'stomach', 'stood', 'stop', 'stopped', 'store', 'strange', 'strangers', 'strawberry', 'street', 'stretch', 'strike', 'strings', 'strip', 'struck', 'struggle', 'stuff', 'stuffed', 'stupid', 'style', 'styrofoam', 'sub', 'subpar', 'subway', 'succulent', 'such', 'suck', 'sucked', 'sucker', 'sucks', 'suffers', 'sugar', 'sugary', 'suggest', 'suggestions', 'summarize', 'summary', 'summer', 'sun', 'sunday', 'sunglasses', 'super', 'supposed', 'sure', 'surprise', 'surprised', 'sushi', 'sweet', 'swung', 'table', 'tables', 'taco', 'tacos', 'tailored', 'take', 'takeout', 'talk', 'talking', 'tap', 'tapas', 'tartar', 'tartare', 'taste', 'tasted', 'tasteless', 'tastings', 'tasty', 'tater', 'tea', 'teamwork', 'teeth', 'tell', 'tempi', 'ten', 'tender', 'tenders', 'tepid', 'terrible', 'terrific', 'texture', 'thai', 'than', 'thanks', 'that', 'thats', 'the', 'theft', 'their', 'them', 'themselves', 'then', 'there', 'these', 'they', 'theyd', 'theyre', 'thick', 'thin', 'thing', 'things', 'think', 'thinking', 'thinly', 'third', 'thirty', 'this', 'thoroughly', 'those', 'though', 'thought', 'three', 'thrilled', 'thru', 'thumbs', 'thus', 'tigerlilly', 'time', 'times', 'tiny', 'tip', 'tiramisu', 'to', 'toast', 'toasted', 'today', 'together', 'togo', 'told', 'tolerance', 'tomato', 'tongue', 'tonight', 'too', 'took', 'top', 'topic', 'tops', 'topvery', 'toro', 'total', 'totally', 'tots', 'touch', 'touched', 'tough', 'towards', 'town', 'traditional', 'tragedy', 'transcendant', 'trap', 'treat', 'treated', 'tribute', 'tried', 'trimmed', 'trip', 'trippy', 'trips', 'truffle', 'truly', 'try', 'trying', 'tucson', 'tummy', 'tuna', 'turkey', 'turn', 'tvs', 'twice', 'two', 'typical', 'unbelievable', 'unbelievably', 'under', 'undercooked', 'underservices', 'understand', 'underwhelming', 'unexperienced', 'unfortunately', 'unhealthy', 'uninspired', 'unique', 'unless', 'unprofessional', 'unreal', 'unsatisfying', 'until', 'untoasted', 'unwelcome', 'unwrapped', 'up', 'updatewent', 'upgrading', 'uploaded', 'upway', 'us', 'use', 'used', 'usual', 'vacant', 'vain', 'valley', 'value', 'vanilla', 'veal', 'veganveggie', 'vegas', 'vegasthere', 'vegetables', 'vegetarian', 'veggitarian', 'velvet', 'ventilation', 'venture', 'venturing', 'venue', 'verge', 'version', 'very', 'via', 'vibe', 'vinaigrette', 'vinegrette', 'violinists', 'visit', 'visited', 'vodka', 'vomited', 'voodoo', 'voted', 'waaaaaayyyyyyyyyy', 'wagyu', 'wait', 'waited', 'waiter', 'waiting', 'waitress', 'waitresses', 'walked', 'wall', 'walls', 'want', 'wanted', 'wants', 'warm', 'warmer', 'warnings', 'was', 'wash', 'wasnt', 'waste', 'wasted', 'wasting', 'watch', 'watched', 'water', 'watered', 'wave', 'way', 'ways', 'wayyy', 'we', 'weak', 'website', 'wed', 'wedges', 'week', 'weekend', 'weekly', 'weird', 'welcome', 'well', 'went', 'were', 'werent', 'weve', 'what', 'whatsoever', 'when', 'whenever', 'where', 'whether', 'which', 'while', 'white', 'who', 'whole', 'why', 'wide', 'wienerschnitzel', 'wife', 'wildly', 'will', 'wine', 'wines', 'wings', 'winner', 'wire', 'wish', 'with', 'without', 'witnessed', 'wonderful', 'wont', 'wontons', 'word', 'words', 'work', 'worker', 'workers', 'workingeating', 'works', 'world', 'worlds', 'worries', 'worse', 'worst', 'worstannoying', 'worth', 'would', 'wouldnt', 'wouldve', 'wound', 'wow', 'wrap', 'wrapped', 'writing', 'wrong', 'yaall', 'yama', 'yay', 'yeah', 'year', 'years', 'yellow', 'yellowtail', 'yelpers', 'yet', 'you', 'youd', 'youll', 'your', 'youre', 'yourself', 'yucky', 'yukon', 'yum', 'yummy', 'zero']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DPSYOPS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vect = CountVectorizer(analyzer='word')\n",
        "X_counts = count_vect.fit_transform(r_data['Review_text_clean'])\n",
        "\n",
        "print(X_counts.shape)\n",
        "print(count_vect.get_feature_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f40420f5",
      "metadata": {
        "id": "f40420f5"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bdfd6eb",
      "metadata": {
        "id": "1bdfd6eb",
        "outputId": "9593d091-f0a3-44d2-d601-afddfc7f6f70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train: 800\n",
            "X_test: 200\n",
            "y_train: 800\n",
            "y_test: 200\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = r_data.Review_text_clean\n",
        "y = r_data.Liked\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=225)\n",
        "\n",
        "print('X_train:', len(X_train))\n",
        "print('X_test:', len(X_test))\n",
        "print('y_train:', len(y_train))\n",
        "print('y_test:', len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c47c1c9",
      "metadata": {
        "id": "1c47c1c9",
        "outputId": "6414b5a0-ca19-466c-f728-59425c02e845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn-pipeline-utils\n",
            "  Downloading scikit_learn_pipeline_utils-0.0.7-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: pandas in c:\\users\\dpsyops\\anaconda3\\lib\\site-packages (from scikit-learn-pipeline-utils) (1.4.2)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\dpsyops\\anaconda3\\lib\\site-packages (from scikit-learn-pipeline-utils) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\dpsyops\\anaconda3\\lib\\site-packages (from pandas->scikit-learn-pipeline-utils) (1.21.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\dpsyops\\anaconda3\\lib\\site-packages (from pandas->scikit-learn-pipeline-utils) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dpsyops\\anaconda3\\lib\\site-packages (from pandas->scikit-learn-pipeline-utils) (2021.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\dpsyops\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->scikit-learn-pipeline-utils) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dpsyops\\anaconda3\\lib\\site-packages (from scikit-learn->scikit-learn-pipeline-utils) (2.2.0)\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\users\\dpsyops\\anaconda3\\lib\\site-packages (from scikit-learn->scikit-learn-pipeline-utils) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\dpsyops\\anaconda3\\lib\\site-packages (from scikit-learn->scikit-learn-pipeline-utils) (1.7.3)\n",
            "Installing collected packages: scikit-learn-pipeline-utils\n",
            "Successfully installed scikit-learn-pipeline-utils-0.0.7\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-learn-pipeline-utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9534e34",
      "metadata": {
        "id": "a9534e34"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "\n",
        "logreg = LogisticRegression(solver='lbfgs')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8261730d",
      "metadata": {
        "scrolled": true,
        "id": "8261730d",
        "outputId": "949266a0-95f9-44de-e027-91215b983ab1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
              "                ('classifer', LogisticRegression())])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model = Pipeline([('vectorizer', tfidf_vect),('classifer', logreg)])\n",
        "model.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cf01051",
      "metadata": {
        "id": "6cf01051",
        "outputId": "10e9f4b2-41c7-43c2-f3d1-3c8c2acedd5e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[82, 17],\n",
              "       [17, 84]], dtype=int64)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_predictions = model.predict(X_test)\n",
        "confusion_matrix(y_predictions, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16113f3b",
      "metadata": {
        "id": "16113f3b",
        "outputId": "c520ad1f-00b4-4bc5-d297-a960a24aa8c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Accuracy is  83.0 %\n",
            "Precision is  0.83\n",
            "Recall is  0.83\n"
          ]
        }
      ],
      "source": [
        "#Accuracy for Logistic regression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "score1 = accuracy_score(y_test,y_predictions)\n",
        "score2 = precision_score(y_test,y_predictions)\n",
        "score3= recall_score(y_test,y_predictions)\n",
        "print(\"\\n\")\n",
        "print(\"Accuracy is \",round(score1*100,2),\"%\")\n",
        "print(\"Precision is \",round(score2,2))\n",
        "print(\"Recall is \",round(score3,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c6d872d",
      "metadata": {
        "id": "6c6d872d",
        "outputId": "babd9386-88f5-432b-dc10-06dcb9676c6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
              "                ('classifer', RandomForestClassifier())])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "Rd = RandomForestClassifier()\n",
        "model = Pipeline([('vectorizer', tfidf_vect),('classifer', Rd)])\n",
        "model.fit(X_train,y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4651dbac",
      "metadata": {
        "id": "4651dbac",
        "outputId": "1034766e-9836-45d1-cecc-9495f96840e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[74, 20],\n",
              "       [25, 81]], dtype=int64)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Predicting Test Results\n",
        "y_predictions = model.predict(X_test)\n",
        "confusion_matrix(y_predictions, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3369da7",
      "metadata": {
        "id": "e3369da7",
        "outputId": "96272d5c-f1e0-4ca2-8632-5e70e34ae95f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Accuracy is  77.5 %\n",
            "Precision is  0.76\n",
            "Recall is  0.8\n"
          ]
        }
      ],
      "source": [
        "# Accuracy for Random Forest Classifier\n",
        "score1 = accuracy_score(y_test,y_predictions)\n",
        "score2 = precision_score(y_test,y_predictions)\n",
        "score3= recall_score(y_test,y_predictions)\n",
        "print(\"\\n\")\n",
        "print(\"Accuracy is \",round(score1*100,2),\"%\")\n",
        "print(\"Precision is \",round(score2,2))\n",
        "print(\"Recall is \",round(score3,2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e5e8484",
      "metadata": {
        "id": "4e5e8484"
      },
      "source": [
        "# Analysis and Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb30cbb5",
      "metadata": {
        "id": "fb30cbb5"
      },
      "source": [
        "In this study, an attempt has been made to classify sentiment analysis for restaurant reviewsusing machine learning techniques. Two algorithms used are namely Logistic Regression and Random Forest Classifer.\n",
        "\n",
        "Evaluation metrics used here are accuracy, precision and recall.\n",
        "\n",
        "Using Logistic Regresssion,\n",
        "Accuracy of prediction is 83.0%\n",
        "Precision of prediction is 0.83%\n",
        "Recall of prediction is 0.83%\n",
        "\n",
        "Using Random Forest Classifier,\n",
        "Accuracy of prediction is 77.5%\n",
        "Precision of prediction is 0.76%\n",
        "Recall of prediction is 0.8%\n",
        "\n",
        "From the above results, Random Forest Classifier is slightly better method compared to Logistic Regression, with 83% accuracy which means the model built for the prediction of sentiment of the restaurantreview gives 83.0% right prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7777e23",
      "metadata": {
        "id": "d7777e23"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}